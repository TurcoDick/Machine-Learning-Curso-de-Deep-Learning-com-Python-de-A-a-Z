{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('../datasets/entradas-breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.0000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>205.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
       "0         17.99          10.38           122.80      1001.0           0.11840   \n",
       "1         20.57          17.77           132.90      1326.0           0.08474   \n",
       "2         19.69          21.25           130.00      1203.0           0.10960   \n",
       "3         11.42          20.38            77.58       386.1           0.14250   \n",
       "4         20.29          14.34           135.10      1297.0           0.10030   \n",
       "\n",
       "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
       "0            0.27760           0.3001              0.14710          0.2419   \n",
       "1            0.07864           0.0869              0.07017          0.1812   \n",
       "2            0.15990           0.1974              0.12790          0.2069   \n",
       "3            0.28390           0.2414              0.10520          0.2597   \n",
       "4            0.13280         198.0000              0.10430          0.1809   \n",
       "\n",
       "    fractal_dimension_mean            ...              radius_worst  \\\n",
       "0                  0.07871            ...                     25.38   \n",
       "1                  0.05667            ...                     24.99   \n",
       "2                  0.05999            ...                     23.57   \n",
       "3                  0.09744            ...                     14.91   \n",
       "4                  0.05883            ...                     22.54   \n",
       "\n",
       "    texture_worst   perimeter_worst   area_worst   smoothness_worst  \\\n",
       "0           17.33            184.60       2019.0             0.1622   \n",
       "1           23.41            158.80       1956.0             0.1238   \n",
       "2           25.53            152.50       1709.0             0.1444   \n",
       "3           26.50             98.87        567.7             0.2098   \n",
       "4           16.67            152.20       1575.0             0.1374   \n",
       "\n",
       "    compactness_worst   concavity_worst   concave_points_worst  \\\n",
       "0              0.6656            0.7119                 0.2654   \n",
       "1              0.1866            0.2416               186.0000   \n",
       "2              0.4245            0.4504               243.0000   \n",
       "3              0.8663            0.6869                 0.2575   \n",
       "4            205.0000            0.4000                 0.1625   \n",
       "\n",
       "    symmetry_worst   fractal_dimension_worst  \n",
       "0           0.4601                   0.11890  \n",
       "1         275.0000                   0.08902  \n",
       "2           0.3613                   0.08758  \n",
       "3           0.6638                 173.00000  \n",
       "4           0.2364                   0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este arquivo sÃ£o dos resultados que jÃ¡ sÃ£o conhecidos\n",
    "classe = pd.read_csv('../datasets/saidas-breast.csv')\n",
    "classe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para dividir a base de dados em treinamento e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento , previsores_teste, classe_treinamento, classe_teste =  train_test_split(\n",
    "    previsores, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alison/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# criando a estrutura para a rede neural\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construindo a primeira camada oculta e a definiÃ§Ã£o da camada de entrada\n",
    "# aqui eu posso colocar um for para criar quantas camadas ocultas eu queira\n",
    "classificador = Sequential()\n",
    "\n",
    "for camada in range(10):\n",
    "    classificador.add(Dense(units = 16, \n",
    "                            activation='relu',\n",
    "                            kernel_initializer='random_uniform',\n",
    "                            input_dim = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camada de saÃ­da\n",
    "# aqui usamos a funÃ§Ã£o sigmoid por que o esultado esperado Ã© 0 ou 1\n",
    "classificador.add(Dense(units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = keras.optimizers.Adam(lr=0.001, decay=0.0001, clipvalue= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurando a rede neural\n",
    "classificador.compile(optimizer = otimizador, loss='binary_crossentropy',metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "426/426 [==============================] - 1s 1ms/step - loss: 0.6872 - binary_accuracy: 0.6338\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.6669 - binary_accuracy: 0.6362\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 178us/step - loss: 0.6213 - binary_accuracy: 0.6362\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.5545 - binary_accuracy: 0.6362\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.5218 - binary_accuracy: 0.6362\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 181us/step - loss: 0.5048 - binary_accuracy: 0.7676\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.4822 - binary_accuracy: 0.8615\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 174us/step - loss: 0.4395 - binary_accuracy: 0.8826\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 181us/step - loss: 0.3993 - binary_accuracy: 0.9038\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 196us/step - loss: 0.3224 - binary_accuracy: 0.8991\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 164us/step - loss: 0.2634 - binary_accuracy: 0.9085\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.2583 - binary_accuracy: 0.9038\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 183us/step - loss: 0.2308 - binary_accuracy: 0.9061\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 162us/step - loss: 0.2674 - binary_accuracy: 0.8967\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.2246 - binary_accuracy: 0.9108\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 184us/step - loss: 0.2034 - binary_accuracy: 0.9202\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 182us/step - loss: 0.1812 - binary_accuracy: 0.9366\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1934 - binary_accuracy: 0.9225\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1823 - binary_accuracy: 0.9249\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.1885 - binary_accuracy: 0.9296\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 168us/step - loss: 0.1826 - binary_accuracy: 0.9272\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 189us/step - loss: 0.1832 - binary_accuracy: 0.9296\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 161us/step - loss: 0.1769 - binary_accuracy: 0.9390\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 172us/step - loss: 0.1793 - binary_accuracy: 0.9343\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.1753 - binary_accuracy: 0.9390\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 182us/step - loss: 0.1722 - binary_accuracy: 0.9272\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.1885 - binary_accuracy: 0.9155\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 179us/step - loss: 0.1726 - binary_accuracy: 0.9225\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.1722 - binary_accuracy: 0.9319\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 183us/step - loss: 0.1652 - binary_accuracy: 0.9225\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.1621 - binary_accuracy: 0.9460\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 180us/step - loss: 0.1885 - binary_accuracy: 0.9366\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 188us/step - loss: 0.1672 - binary_accuracy: 0.9437\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 184us/step - loss: 0.1753 - binary_accuracy: 0.9272\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.1621 - binary_accuracy: 0.9413\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.2029 - binary_accuracy: 0.9061\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 189us/step - loss: 0.2395 - binary_accuracy: 0.9155\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 181us/step - loss: 0.1526 - binary_accuracy: 0.9507\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 161us/step - loss: 0.1815 - binary_accuracy: 0.9296\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.1405 - binary_accuracy: 0.9460\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 183us/step - loss: 0.1583 - binary_accuracy: 0.9366\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 195us/step - loss: 0.1994 - binary_accuracy: 0.9319\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1368 - binary_accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 187us/step - loss: 0.1494 - binary_accuracy: 0.9531\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 181us/step - loss: 0.1947 - binary_accuracy: 0.9296\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 180us/step - loss: 0.1647 - binary_accuracy: 0.9507\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 173us/step - loss: 0.1509 - binary_accuracy: 0.9413\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 180us/step - loss: 0.1572 - binary_accuracy: 0.9390\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.1286 - binary_accuracy: 0.9484\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.1540 - binary_accuracy: 0.9437\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 180us/step - loss: 0.1727 - binary_accuracy: 0.9366\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 154us/step - loss: 0.1472 - binary_accuracy: 0.9390\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.1341 - binary_accuracy: 0.9507\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 159us/step - loss: 0.1553 - binary_accuracy: 0.9413\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1486 - binary_accuracy: 0.9390\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 188us/step - loss: 0.1692 - binary_accuracy: 0.9437\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 165us/step - loss: 0.1409 - binary_accuracy: 0.9507\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 195us/step - loss: 0.1517 - binary_accuracy: 0.9366\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 156us/step - loss: 0.1545 - binary_accuracy: 0.9413\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.1580 - binary_accuracy: 0.9531\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.1423 - binary_accuracy: 0.9554\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 190us/step - loss: 0.1543 - binary_accuracy: 0.9366\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 188us/step - loss: 0.1474 - binary_accuracy: 0.9437\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 153us/step - loss: 0.1561 - binary_accuracy: 0.9390\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.3191 - binary_accuracy: 0.9296\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.1689 - binary_accuracy: 0.9366\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 164us/step - loss: 0.1876 - binary_accuracy: 0.9272\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 161us/step - loss: 0.2202 - binary_accuracy: 0.9319\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 158us/step - loss: 0.6527 - binary_accuracy: 0.9061\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.4781 - binary_accuracy: 0.9319\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.5192 - binary_accuracy: 0.9343\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.5559 - binary_accuracy: 0.8991\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.5070 - binary_accuracy: 0.9319\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 168us/step - loss: 0.5196 - binary_accuracy: 0.9296\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.4945 - binary_accuracy: 0.9366\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.5215 - binary_accuracy: 0.9272\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 159us/step - loss: 0.5203 - binary_accuracy: 0.9202\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 164us/step - loss: 0.5077 - binary_accuracy: 0.9296\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 154us/step - loss: 0.5159 - binary_accuracy: 0.9249\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 154us/step - loss: 0.6303 - binary_accuracy: 0.9038\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 160us/step - loss: 0.5336 - binary_accuracy: 0.9202\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 160us/step - loss: 0.5183 - binary_accuracy: 0.9249\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.6009 - binary_accuracy: 0.9108\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.6946 - binary_accuracy: 0.9085\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 172us/step - loss: 0.5297 - binary_accuracy: 0.9343\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 151us/step - loss: 0.5366 - binary_accuracy: 0.9249\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.6246 - binary_accuracy: 0.9178\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 160us/step - loss: 0.6975 - binary_accuracy: 0.9178\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 149us/step - loss: 0.6711 - binary_accuracy: 0.9202\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 159us/step - loss: 0.5631 - binary_accuracy: 0.9202\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.7205 - binary_accuracy: 0.9085\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 156us/step - loss: 0.7196 - binary_accuracy: 0.9014\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.7031 - binary_accuracy: 0.9225\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 162us/step - loss: 0.7032 - binary_accuracy: 0.9085\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.6958 - binary_accuracy: 0.9178\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 157us/step - loss: 0.7217 - binary_accuracy: 0.9108\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.7101 - binary_accuracy: 0.9061\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.7155 - binary_accuracy: 0.9038\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.7212 - binary_accuracy: 0.9038\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 158us/step - loss: 0.6956 - binary_accuracy: 0.9225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4a3299e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizar o treinamento\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.25556728e-02,  2.45753601e-02, -1.01008877e-01,\n",
       "         -1.23195373e-01, -5.55193983e-02, -6.58134371e-02,\n",
       "         -1.62374765e-01,  8.23350027e-02,  6.82463124e-03,\n",
       "          1.33581758e-01, -3.63794491e-02,  1.06249005e-02,\n",
       "          1.12909429e-01,  6.86609894e-02,  1.93147324e-02,\n",
       "          1.63417459e-01],\n",
       "        [ 1.29700258e-01,  2.90057093e-01, -1.21423759e-01,\n",
       "         -1.77029043e-01,  1.12296060e-01, -1.34911135e-01,\n",
       "         -1.26042351e-01, -2.70488113e-02,  2.18061786e-02,\n",
       "          2.77713478e-01, -4.45668213e-02,  2.63883293e-01,\n",
       "         -9.10008233e-03,  5.02539016e-02,  6.49667457e-02,\n",
       "         -3.34824100e-02],\n",
       "        [-3.98019888e-02,  7.43982196e-02, -2.36230969e-01,\n",
       "         -1.60018519e-01,  3.54208238e-02, -6.38438538e-02,\n",
       "         -1.58942997e-01,  2.25901641e-02, -7.01150820e-02,\n",
       "          3.54735292e-02,  2.36304328e-02,  8.17933306e-02,\n",
       "         -7.52509907e-02,  5.34281619e-02, -5.40359840e-02,\n",
       "         -6.97187260e-02],\n",
       "        [-9.11532417e-02, -3.23902927e-02, -1.49142951e-01,\n",
       "         -2.07371727e-01,  8.63932371e-02, -1.68495685e-01,\n",
       "         -9.23196077e-02, -9.29848701e-02, -4.79923561e-02,\n",
       "         -6.64936155e-02,  1.94824617e-02,  1.13471262e-02,\n",
       "         -8.51085410e-02, -1.77156162e-02, -5.27729243e-02,\n",
       "         -3.79694588e-02],\n",
       "        [ 1.03990160e-01,  1.35631576e-01, -1.71290427e-01,\n",
       "         -1.54729396e-01,  2.51737982e-01, -7.22389370e-02,\n",
       "         -1.49646746e-02, -4.37409878e-02,  6.24171924e-03,\n",
       "          9.79086384e-02, -2.71260384e-02,  2.39199698e-01,\n",
       "         -7.40764961e-02,  5.75097539e-02, -1.88098013e-01,\n",
       "          8.97731707e-02],\n",
       "        [ 5.08598890e-03,  8.92039537e-02, -1.19736977e-01,\n",
       "         -1.34373814e-01,  2.09781617e-01, -3.67249064e-02,\n",
       "         -1.45322934e-01, -3.40917632e-02,  1.17741562e-02,\n",
       "          8.74513760e-02, -6.19191155e-02, -2.61043888e-02,\n",
       "          1.91484839e-02,  5.32933977e-03, -1.12699740e-01,\n",
       "         -2.71753035e-02],\n",
       "        [ 1.90091744e-01,  5.09912856e-02,  1.06052026e-01,\n",
       "          5.12902141e-02,  1.12396978e-01,  8.33332092e-02,\n",
       "          2.56247614e-02,  6.81073070e-02,  8.46557394e-02,\n",
       "          4.09221537e-02, -5.75447753e-02, -3.92859839e-02,\n",
       "         -2.88197231e-02,  2.98445486e-03,  5.30214012e-02,\n",
       "          1.07407361e-01],\n",
       "        [ 1.94981731e-02, -1.50247335e-01,  1.08137615e-01,\n",
       "          1.05986893e-01, -3.67238432e-01,  4.24597859e-02,\n",
       "          2.14550942e-01,  1.29297301e-01, -4.23641242e-02,\n",
       "         -1.67785719e-01, -3.04296482e-02, -1.57992080e-01,\n",
       "          1.52044231e-02, -5.65683618e-02,  1.62021872e-02,\n",
       "          5.94252013e-02],\n",
       "        [-1.05989147e-02, -4.24979217e-02,  1.01083897e-01,\n",
       "          2.16592148e-01, -1.41761169e-01,  1.78309396e-01,\n",
       "          9.43487659e-02,  4.17240076e-02,  2.31264532e-02,\n",
       "         -8.25158060e-02, -4.09328155e-02, -7.68265575e-02,\n",
       "          7.64099474e-04,  1.17379939e-03, -3.37412432e-02,\n",
       "          8.10834244e-02],\n",
       "        [ 7.91954622e-02,  1.78702082e-02, -6.66667596e-02,\n",
       "          3.66073698e-02,  2.35170741e-02,  1.50606595e-02,\n",
       "         -5.31492941e-02,  1.58793423e-02,  1.24267906e-01,\n",
       "          1.85601301e-02, -4.89041507e-02, -5.43840379e-02,\n",
       "          1.54604623e-02,  3.07914913e-01, -1.21809393e-02,\n",
       "          1.26831174e-01],\n",
       "        [-1.19307600e-02,  5.58496006e-02, -2.39372030e-01,\n",
       "         -3.00487846e-01, -2.04319507e-02, -2.83626560e-02,\n",
       "         -2.46910051e-01, -1.97045535e-01, -2.42384765e-02,\n",
       "         -8.82393029e-03, -1.34566491e-02, -7.49045564e-03,\n",
       "          4.08412814e-02, -5.11360262e-03, -1.41142264e-01,\n",
       "         -7.47194439e-02],\n",
       "        [-1.52543532e-02, -6.48496822e-02,  5.46972118e-02,\n",
       "          6.09546527e-02, -1.06585778e-01,  2.62442566e-02,\n",
       "          1.11383319e-01,  2.38087103e-02, -6.27603903e-02,\n",
       "         -5.21599874e-03, -3.28683294e-02, -8.53434578e-02,\n",
       "          3.02004777e-02,  1.35657722e-02,  1.46252066e-02,\n",
       "         -3.96135412e-02],\n",
       "        [-9.65059642e-03, -6.65080408e-03,  5.42517640e-02,\n",
       "          6.93755448e-02, -1.72042344e-02,  5.49950004e-02,\n",
       "          5.87639026e-03,  2.58405022e-02,  1.56520382e-02,\n",
       "         -5.50938305e-04,  4.64743236e-03,  1.44121936e-02,\n",
       "          2.26971786e-02, -5.16288728e-02, -9.04713292e-03,\n",
       "          4.29069661e-02],\n",
       "        [ 2.67515302e-01,  3.19532812e-01, -3.21586490e-01,\n",
       "         -1.94144294e-01, -1.45053798e-02, -3.94816883e-02,\n",
       "         -2.28552267e-01,  6.63922206e-02,  1.92720413e-01,\n",
       "          4.28316414e-01, -4.93649254e-03,  3.42118055e-01,\n",
       "         -5.52381799e-02,  1.22950397e-01,  1.91029683e-02,\n",
       "          2.03111559e-01],\n",
       "        [ 2.24303588e-01,  3.25664997e-01, -1.91571355e-01,\n",
       "         -1.60271779e-01, -4.80303243e-02, -1.79001570e-01,\n",
       "         -2.02297851e-01, -3.84385437e-02,  2.95204520e-02,\n",
       "          3.93838674e-01, -3.49187758e-03,  3.15133065e-01,\n",
       "         -6.96736649e-02,  2.02464256e-02,  1.09815150e-01,\n",
       "         -1.13011822e-02],\n",
       "        [-1.90209016e-01, -8.11896548e-02,  4.15937006e-02,\n",
       "          1.34886848e-02,  8.50826427e-02, -3.92622985e-02,\n",
       "          7.04450533e-02,  2.10094154e-02, -5.68209402e-03,\n",
       "         -7.45587647e-02, -5.19909263e-02, -1.51718572e-01,\n",
       "         -3.32307182e-02, -2.74268001e-01, -1.08402111e-01,\n",
       "         -1.00931250e-01],\n",
       "        [-3.05626392e-01, -3.30320448e-01, -1.46370977e-01,\n",
       "         -7.48054385e-02,  6.86191767e-02, -3.02372277e-02,\n",
       "          1.59698442e-01,  8.89103208e-03, -4.35775630e-02,\n",
       "         -1.82118490e-01, -1.31150736e-02, -3.37417424e-01,\n",
       "         -9.09690857e-02,  9.02676582e-02, -2.51552284e-01,\n",
       "         -2.99569312e-02],\n",
       "        [ 5.43689907e-01,  5.52100062e-01, -1.40102357e-01,\n",
       "         -1.70064554e-01,  8.74967054e-02, -1.26262531e-01,\n",
       "         -2.72064447e-01, -1.31063852e-02, -3.73361744e-02,\n",
       "          7.45334506e-01, -2.41676532e-02,  6.03307962e-01,\n",
       "         -6.43850565e-02,  1.16947792e-01,  1.70682073e-01,\n",
       "         -6.58147410e-02],\n",
       "        [ 1.31571793e-03,  1.62027813e-02, -8.97331163e-02,\n",
       "         -1.38671264e-01,  2.16115341e-01, -5.05412072e-02,\n",
       "         -1.35203525e-01, -5.33531085e-02,  6.49379790e-02,\n",
       "          2.45617732e-01, -2.00473145e-02,  6.97899684e-02,\n",
       "          3.27397957e-02,  2.89169490e-01,  1.01287782e-01,\n",
       "          1.28269745e-02],\n",
       "        [ 3.66748244e-01,  3.01558197e-01,  1.96654294e-02,\n",
       "          2.71102786e-02,  1.99625880e-01, -3.33686396e-02,\n",
       "         -1.50933117e-01,  3.09183970e-02, -6.08019158e-02,\n",
       "          4.35856581e-01, -1.16246352e-02,  3.32719535e-01,\n",
       "         -5.41265868e-03,  4.81024608e-02,  2.11863250e-01,\n",
       "         -6.45004660e-02],\n",
       "        [ 3.57805267e-02,  1.04032442e-01, -1.92314148e-01,\n",
       "         -1.61559865e-01,  3.39279859e-03, -5.23363948e-02,\n",
       "         -2.20062047e-01,  4.66752686e-02,  1.32945806e-01,\n",
       "          1.79781362e-01, -1.98142584e-02,  5.93465269e-02,\n",
       "         -9.51055530e-03,  9.36817378e-02,  4.50520450e-03,\n",
       "          1.29718497e-01],\n",
       "        [ 2.72575974e-01,  3.32451284e-01, -1.53932393e-01,\n",
       "         -1.35759562e-01,  1.18298173e-01, -8.42519924e-02,\n",
       "         -1.65839106e-01,  2.86680646e-03, -3.87825724e-03,\n",
       "          4.00263458e-01, -6.28870279e-02,  3.25398386e-01,\n",
       "         -5.29271215e-02,  6.47279546e-02,  9.51320678e-02,\n",
       "          2.13160515e-02],\n",
       "        [ 6.64053485e-02,  1.76567212e-01, -1.93976060e-01,\n",
       "         -2.17703789e-01,  8.20903573e-03, -1.17498234e-01,\n",
       "         -1.83908150e-01, -3.92005518e-02, -9.16337315e-03,\n",
       "          7.26050958e-02,  1.25001324e-02,  1.21056668e-01,\n",
       "         -1.01596136e-02,  8.87702927e-02, -9.12891887e-03,\n",
       "         -4.63025421e-02],\n",
       "        [ 1.02234475e-01,  1.49749026e-01, -1.52092740e-01,\n",
       "         -1.37526155e-01,  1.26887962e-01, -1.73378363e-01,\n",
       "         -1.45626202e-01, -8.85708332e-02, -6.62317052e-02,\n",
       "          2.03080829e-02, -7.68191516e-02,  1.61474422e-01,\n",
       "         -8.84361789e-02, -5.37179932e-02, -2.75739525e-02,\n",
       "         -9.12279710e-02],\n",
       "        [-7.30557274e-03,  1.14275731e-01, -6.25562668e-02,\n",
       "          9.29539558e-03,  1.56671986e-01, -4.41727638e-02,\n",
       "         -2.29342818e-01, -1.27025589e-01, -5.87293208e-02,\n",
       "         -3.65466438e-02,  4.03256718e-06,  1.93382174e-01,\n",
       "         -1.09250195e-01,  3.03577948e-02, -2.57520638e-02,\n",
       "         -3.94515656e-02],\n",
       "        [-1.90427732e-02, -2.56177248e-03,  8.33376721e-02,\n",
       "          1.28846213e-01, -6.47781864e-02,  1.90914065e-01,\n",
       "          9.86643285e-02,  2.20902241e-03, -5.55981733e-02,\n",
       "         -8.35142434e-02, -4.08921838e-02,  5.03850207e-02,\n",
       "         -9.10473689e-02, -1.43976277e-02,  1.16329767e-01,\n",
       "         -2.11875476e-02],\n",
       "        [ 3.61714698e-03,  7.86921307e-02,  4.69949059e-02,\n",
       "          6.57386705e-02,  6.32782280e-02,  1.06143668e-01,\n",
       "         -1.62567183e-01, -3.75568159e-02,  1.14888633e-02,\n",
       "         -1.57724023e-01, -5.68921901e-02,  8.06537494e-02,\n",
       "         -6.40659779e-02, -1.36061072e-01,  2.38400716e-02,\n",
       "          1.60130747e-02],\n",
       "        [ 2.57410295e-02, -4.70217830e-03,  2.97015458e-01,\n",
       "          2.11339474e-01, -1.85135156e-02,  1.30908117e-01,\n",
       "          2.56523728e-01, -4.36252952e-02,  5.26378527e-02,\n",
       "         -8.74463245e-02, -1.35835875e-02, -1.23904660e-01,\n",
       "          6.76475689e-02, -9.59061012e-02,  1.64537448e-02,\n",
       "         -6.80667162e-02],\n",
       "        [-7.93316364e-02,  6.00023195e-02, -3.82474326e-02,\n",
       "         -1.48090616e-01, -1.34880682e-02, -2.01041028e-01,\n",
       "         -1.37166977e-01, -1.05735146e-01,  1.46212392e-02,\n",
       "         -4.23101336e-02,  5.09208301e-03,  6.43683448e-02,\n",
       "         -1.18139669e-01, -4.67444137e-02,  1.32773504e-01,\n",
       "         -1.05398700e-01],\n",
       "        [ 4.49962020e-01,  3.95421922e-01, -2.09530350e-02,\n",
       "         -8.81895721e-02,  3.42742413e-01, -8.09803829e-02,\n",
       "         -1.30823299e-01, -5.65235205e-02, -1.39462119e-02,\n",
       "          4.02027071e-01,  1.73967872e-02,  4.56778020e-01,\n",
       "         -1.90950204e-02,  4.83216494e-02,  3.92860360e-02,\n",
       "         -7.11867064e-02]], dtype=float32),\n",
       " array([-0.15238519, -0.04587793, -0.17596598, -0.14802603, -0.00099052,\n",
       "        -0.08079844, -0.11016238,  0.01001203,  0.01270485, -0.03222892,\n",
       "        -0.0267064 , -0.08944897, -0.02256801,  0.03459269, -0.10023724,\n",
       "         0.0395689 ], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizando os valores dos pesos na rede neural\n",
    "pesos0 = classificador.layers[0].get_weights()\n",
    "pesos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando \n",
    "previsores = classificador.predict(previsores_teste)\n",
    "previsores = (previsores > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer a comparaÃ§Ã£o entre as previsÃµes e os reultados que jÃ¡ conheÃ§o\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8531468531468531"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisao = accuracy_score(classe_teste, previsores)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a matriz de confusÃ£o\n",
    "matriz = confusion_matrix(classe_teste,previsores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 12],\n",
       "       [ 9, 77]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 509us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.644016119150015, 0.8531468548141159]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazendo o mesmo comparativo acima mas usando o keras agora\n",
    "resultado = classificador.evaluate(previsores_teste, classe_teste)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
