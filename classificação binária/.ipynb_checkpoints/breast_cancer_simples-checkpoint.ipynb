{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('../datasets/entradas-breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.0000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>205.0000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean   texture_mean   perimeter_mean   area_mean   smoothness_mean  \\\n",
       "0         17.99          10.38           122.80      1001.0           0.11840   \n",
       "1         20.57          17.77           132.90      1326.0           0.08474   \n",
       "2         19.69          21.25           130.00      1203.0           0.10960   \n",
       "3         11.42          20.38            77.58       386.1           0.14250   \n",
       "4         20.29          14.34           135.10      1297.0           0.10030   \n",
       "\n",
       "    compactness_mean   concavity_mean  concave_points_mean   symmetry_mean  \\\n",
       "0            0.27760           0.3001              0.14710          0.2419   \n",
       "1            0.07864           0.0869              0.07017          0.1812   \n",
       "2            0.15990           0.1974              0.12790          0.2069   \n",
       "3            0.28390           0.2414              0.10520          0.2597   \n",
       "4            0.13280         198.0000              0.10430          0.1809   \n",
       "\n",
       "    fractal_dimension_mean            ...              radius_worst  \\\n",
       "0                  0.07871            ...                     25.38   \n",
       "1                  0.05667            ...                     24.99   \n",
       "2                  0.05999            ...                     23.57   \n",
       "3                  0.09744            ...                     14.91   \n",
       "4                  0.05883            ...                     22.54   \n",
       "\n",
       "    texture_worst   perimeter_worst   area_worst   smoothness_worst  \\\n",
       "0           17.33            184.60       2019.0             0.1622   \n",
       "1           23.41            158.80       1956.0             0.1238   \n",
       "2           25.53            152.50       1709.0             0.1444   \n",
       "3           26.50             98.87        567.7             0.2098   \n",
       "4           16.67            152.20       1575.0             0.1374   \n",
       "\n",
       "    compactness_worst   concavity_worst   concave_points_worst  \\\n",
       "0              0.6656            0.7119                 0.2654   \n",
       "1              0.1866            0.2416               186.0000   \n",
       "2              0.4245            0.4504               243.0000   \n",
       "3              0.8663            0.6869                 0.2575   \n",
       "4            205.0000            0.4000                 0.1625   \n",
       "\n",
       "    symmetry_worst   fractal_dimension_worst  \n",
       "0           0.4601                   0.11890  \n",
       "1         275.0000                   0.08902  \n",
       "2           0.3613                   0.08758  \n",
       "3           0.6638                 173.00000  \n",
       "4           0.2364                   0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este arquivo sÃ£o dos resultados que jÃ¡ sÃ£o conhecidos\n",
    "classe = pd.read_csv('../datasets/saidas-breast.csv')\n",
    "classe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para dividir a base de dados em treinamento e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento , previsores_teste, classe_treinamento, classe_teste =  train_test_split(\n",
    "    previsores, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alison/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# criando a estrutura para a rede neural\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construindo a primeira camada oculta e a definiÃ§Ã£o da camada de entrada\n",
    "# aqui eu posso colocar um for para criar quantas camadas ocultas eu queira\n",
    "classificador = Sequential()\n",
    "\n",
    "for camada in range(10):\n",
    "    classificador.add(Dense(units = 16, \n",
    "                            activation='relu',\n",
    "                            kernel_initializer='random_uniform',\n",
    "                            input_dim = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camada de saÃ­da\n",
    "# aqui usamos a funÃ§Ã£o sigmoid por que o esultado esperado Ã© 0 ou 1\n",
    "classificador.add(Dense(units= 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = keras.optimizers.Adam(lr=0.001, decay=0.0001, clipvalue= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurando a rede neural\n",
    "classificador.compile(optimizer = otimizador, loss='binary_crossentropy',metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "426/426 [==============================] - 1s 2ms/step - loss: 0.6872 - binary_accuracy: 0.6103\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 195us/step - loss: 0.6720 - binary_accuracy: 0.6197\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 192us/step - loss: 0.5865 - binary_accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 187us/step - loss: 0.5623 - binary_accuracy: 0.6197\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.5623 - binary_accuracy: 0.6737\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.5090 - binary_accuracy: 0.8404\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 187us/step - loss: 0.4576 - binary_accuracy: 0.8545\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.3610 - binary_accuracy: 0.8685\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 197us/step - loss: 0.3243 - binary_accuracy: 0.8685\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 172us/step - loss: 0.3084 - binary_accuracy: 0.8803\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 179us/step - loss: 0.2711 - binary_accuracy: 0.8967\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 187us/step - loss: 0.2642 - binary_accuracy: 0.8991\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 174us/step - loss: 0.2768 - binary_accuracy: 0.8826\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 225us/step - loss: 0.3104 - binary_accuracy: 0.8826\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 193us/step - loss: 0.2570 - binary_accuracy: 0.9038\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 172us/step - loss: 0.2723 - binary_accuracy: 0.8850\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 177us/step - loss: 0.2229 - binary_accuracy: 0.9108\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.2451 - binary_accuracy: 0.8967\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 168us/step - loss: 0.2642 - binary_accuracy: 0.8967\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 189us/step - loss: 0.2478 - binary_accuracy: 0.9061\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 191us/step - loss: 0.2509 - binary_accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.2272 - binary_accuracy: 0.9061\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 182us/step - loss: 0.2110 - binary_accuracy: 0.9108\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.2013 - binary_accuracy: 0.9225\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 179us/step - loss: 0.2313 - binary_accuracy: 0.9131\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.2102 - binary_accuracy: 0.9131\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 187us/step - loss: 0.2035 - binary_accuracy: 0.9249\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 202us/step - loss: 0.2188 - binary_accuracy: 0.8991\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 224us/step - loss: 0.2236 - binary_accuracy: 0.9108\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 201us/step - loss: 0.1922 - binary_accuracy: 0.9319\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 205us/step - loss: 0.2343 - binary_accuracy: 0.9155\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 205us/step - loss: 0.1851 - binary_accuracy: 0.9272\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 199us/step - loss: 0.2901 - binary_accuracy: 0.9108\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.2145 - binary_accuracy: 0.9202\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 180us/step - loss: 0.2021 - binary_accuracy: 0.9178\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.2508 - binary_accuracy: 0.9014\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 183us/step - loss: 0.2044 - binary_accuracy: 0.9178\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.1782 - binary_accuracy: 0.9319\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 173us/step - loss: 0.1793 - binary_accuracy: 0.9296\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 185us/step - loss: 0.2094 - binary_accuracy: 0.9108\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1774 - binary_accuracy: 0.9178\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.2053 - binary_accuracy: 0.9272\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 174us/step - loss: 0.1709 - binary_accuracy: 0.9343\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 181us/step - loss: 0.2139 - binary_accuracy: 0.9131\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.1691 - binary_accuracy: 0.9390\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 171us/step - loss: 0.1664 - binary_accuracy: 0.9272\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 170us/step - loss: 0.1997 - binary_accuracy: 0.9202\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 188us/step - loss: 0.1513 - binary_accuracy: 0.9366\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 174us/step - loss: 0.1724 - binary_accuracy: 0.9366\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 175us/step - loss: 0.1660 - binary_accuracy: 0.9343\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 162us/step - loss: 0.1710 - binary_accuracy: 0.9343\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 188us/step - loss: 0.1527 - binary_accuracy: 0.9413\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 195us/step - loss: 0.2104 - binary_accuracy: 0.9249\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 147us/step - loss: 0.2828 - binary_accuracy: 0.9202\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.1820 - binary_accuracy: 0.9460\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 159us/step - loss: 0.1487 - binary_accuracy: 0.9413\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.2271 - binary_accuracy: 0.9014\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 165us/step - loss: 0.1525 - binary_accuracy: 0.9390\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1715 - binary_accuracy: 0.9319\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 172us/step - loss: 0.1806 - binary_accuracy: 0.9366\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 176us/step - loss: 0.1796 - binary_accuracy: 0.9272\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 157us/step - loss: 0.1692 - binary_accuracy: 0.9319\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 177us/step - loss: 0.1463 - binary_accuracy: 0.9343\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 153us/step - loss: 0.1378 - binary_accuracy: 0.9366\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 173us/step - loss: 0.1537 - binary_accuracy: 0.9296\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 173us/step - loss: 0.1355 - binary_accuracy: 0.9484\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 163us/step - loss: 0.1598 - binary_accuracy: 0.9390\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 151us/step - loss: 0.1779 - binary_accuracy: 0.9460\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 164us/step - loss: 0.3043 - binary_accuracy: 0.9225\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 169us/step - loss: 0.1451 - binary_accuracy: 0.9577\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 155us/step - loss: 0.2840 - binary_accuracy: 0.9390\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 158us/step - loss: 0.3538 - binary_accuracy: 0.9202\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 154us/step - loss: 0.2446 - binary_accuracy: 0.9202\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 156us/step - loss: 0.1496 - binary_accuracy: 0.9437\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 167us/step - loss: 0.1526 - binary_accuracy: 0.9390\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 143us/step - loss: 0.2115 - binary_accuracy: 0.9272\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 161us/step - loss: 0.4126 - binary_accuracy: 0.9178\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 151us/step - loss: 0.4347 - binary_accuracy: 0.9249\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 156us/step - loss: 0.4124 - binary_accuracy: 0.9108\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.4283 - binary_accuracy: 0.9178\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 142us/step - loss: 0.5862 - binary_accuracy: 0.9272\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.6081 - binary_accuracy: 0.9178\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.6879 - binary_accuracy: 0.9014\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.6227 - binary_accuracy: 0.9038\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 150us/step - loss: 0.6831 - binary_accuracy: 0.8850\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 147us/step - loss: 0.6340 - binary_accuracy: 0.9085\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 143us/step - loss: 0.6493 - binary_accuracy: 0.8967\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.6182 - binary_accuracy: 0.9131\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 161us/step - loss: 0.8162 - binary_accuracy: 0.9014\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 156us/step - loss: 0.8645 - binary_accuracy: 0.8873\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 157us/step - loss: 0.8258 - binary_accuracy: 0.8944\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 144us/step - loss: 0.8466 - binary_accuracy: 0.8897\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 206us/step - loss: 0.8508 - binary_accuracy: 0.8920\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 166us/step - loss: 0.8574 - binary_accuracy: 0.8873\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 153us/step - loss: 0.8652 - binary_accuracy: 0.8850\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 148us/step - loss: 0.9617 - binary_accuracy: 0.8498\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 152us/step - loss: 0.8762 - binary_accuracy: 0.8873\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 147us/step - loss: 0.8540 - binary_accuracy: 0.8850\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 144us/step - loss: 0.8579 - binary_accuracy: 0.8873\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 146us/step - loss: 0.8874 - binary_accuracy: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a1235ec88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizar o treinamento\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.36135057e-01,  2.46622622e-01,  7.77387805e-03,\n",
       "          1.27302930e-01,  2.00007170e-01, -7.97526985e-02,\n",
       "          7.49422424e-03,  1.55189037e-01, -1.09070219e-01,\n",
       "         -1.35338297e-02,  3.74036618e-02,  2.66155563e-02,\n",
       "          4.23919782e-02,  1.84493214e-02, -8.62729549e-03,\n",
       "          8.39411989e-02],\n",
       "        [-1.73405617e-01,  3.09401602e-01, -1.34887308e-01,\n",
       "          6.67778717e-04,  1.12329051e-01, -2.47166142e-01,\n",
       "          2.35186115e-01,  2.57546399e-02, -1.83931738e-01,\n",
       "          4.68703397e-02,  1.16032198e-01,  3.06728601e-01,\n",
       "          1.44067824e-01, -2.21506685e-01, -6.91851228e-03,\n",
       "         -1.00281462e-01],\n",
       "        [-2.87257433e-02,  1.72962248e-01, -9.40148160e-02,\n",
       "         -8.45863670e-02,  8.78998116e-02, -1.73533913e-02,\n",
       "          1.00203343e-01, -5.24250306e-02, -1.00031808e-01,\n",
       "         -6.98187128e-02,  6.69827312e-02,  1.08517297e-01,\n",
       "          3.83154713e-02, -7.66140148e-02, -1.13709681e-02,\n",
       "         -8.64315405e-02],\n",
       "        [-2.88309809e-02, -6.42877072e-02,  9.50178728e-02,\n",
       "          4.78114523e-02, -1.09370477e-01,  1.57187507e-01,\n",
       "          4.91899364e-02, -2.80126110e-02, -1.45850822e-01,\n",
       "          8.66197050e-03, -1.33281425e-01, -1.09447902e-02,\n",
       "         -1.22209907e-01,  7.11998641e-02, -8.24714825e-03,\n",
       "         -1.05845802e-01],\n",
       "        [ 1.86612681e-01,  1.77195236e-01,  1.45096413e-03,\n",
       "         -3.36086899e-02, -7.57856518e-02, -4.20663983e-01,\n",
       "          1.04899533e-01,  3.57059240e-02, -8.67630243e-02,\n",
       "         -1.46583781e-01,  1.02888227e-01,  8.98814276e-02,\n",
       "         -1.50348052e-01, -3.44013721e-02, -2.65044700e-02,\n",
       "          1.04497366e-01],\n",
       "        [ 8.53926316e-02, -4.32089716e-03,  4.81846510e-03,\n",
       "         -1.08448900e-02,  1.02994993e-01, -7.92478696e-02,\n",
       "         -6.90056831e-02, -1.74989942e-02, -5.14678210e-02,\n",
       "         -4.23859417e-01,  1.23644136e-02, -3.51624824e-02,\n",
       "         -5.12593761e-02,  9.17038023e-02, -1.43363960e-02,\n",
       "          1.05626307e-01],\n",
       "        [ 6.97574839e-02,  2.09762961e-01,  5.77880666e-02,\n",
       "          4.44121473e-03,  1.09055154e-01,  5.14608482e-03,\n",
       "          5.01853637e-02,  2.80008782e-02,  1.88993230e-01,\n",
       "         -4.63991523e-01, -9.14615914e-02,  1.69493128e-02,\n",
       "          5.14147058e-02, -4.76842001e-02,  3.89400162e-02,\n",
       "          1.22579329e-01],\n",
       "        [ 8.85729939e-02, -4.76192031e-03, -1.22070365e-01,\n",
       "         -2.00703114e-01, -1.54544339e-01, -4.11267072e-01,\n",
       "         -1.15788475e-01, -7.27952458e-03,  3.85017425e-01,\n",
       "         -1.25444844e-01, -1.58981115e-01, -1.33057401e-01,\n",
       "          3.04085799e-02, -4.94354405e-02, -3.52580920e-02,\n",
       "          1.42841652e-01],\n",
       "        [ 3.06532294e-01, -1.05484121e-01, -5.00048220e-01,\n",
       "         -7.50913620e-02,  8.04278851e-02,  6.71271682e-02,\n",
       "         -2.19219700e-02,  7.41472933e-03,  2.70886511e-01,\n",
       "          3.10717314e-01, -4.48059998e-02, -6.03935570e-02,\n",
       "         -6.05845870e-03,  8.23932141e-02,  6.62889332e-03,\n",
       "          9.58827958e-02],\n",
       "        [ 2.77009398e-01, -5.78146689e-02,  2.38574639e-01,\n",
       "          2.06052095e-01,  3.20523120e-02,  1.13123797e-01,\n",
       "         -2.54775286e-01,  4.22866605e-02,  1.02852769e-01,\n",
       "          1.72213450e-01,  9.85825881e-02, -1.98387712e-01,\n",
       "         -3.16399820e-02,  2.00450972e-01, -3.91069539e-02,\n",
       "          9.59441662e-02],\n",
       "        [-1.59403309e-01, -1.12975813e-01,  1.88113376e-02,\n",
       "         -1.21393114e-01, -7.63089024e-03,  4.54822928e-02,\n",
       "          1.18566826e-02,  6.23333035e-03, -2.27125704e-01,\n",
       "          1.29101016e-02, -1.37991741e-01,  7.33617768e-02,\n",
       "         -1.20063491e-01, -1.50321797e-02, -4.78566065e-02,\n",
       "          1.02636060e-02],\n",
       "        [ 1.97078824e-01,  1.01778626e-01, -3.28102335e-02,\n",
       "          1.01047508e-01,  2.67292932e-02, -3.60879958e-01,\n",
       "         -9.49297473e-02, -1.71106793e-02,  4.47682776e-02,\n",
       "         -2.87095476e-02,  5.18566184e-02, -1.07586198e-01,\n",
       "         -2.28701904e-02,  4.96441834e-02, -5.56625426e-04,\n",
       "          4.03471328e-02],\n",
       "        [ 8.29724520e-02, -4.78433035e-02,  6.21296978e-03,\n",
       "          2.37546843e-02,  2.10715607e-02,  8.81200954e-02,\n",
       "          6.91147000e-02, -9.12112463e-03,  4.74996865e-02,\n",
       "         -1.09179355e-01,  3.00535802e-02,  7.90005252e-02,\n",
       "          6.19266331e-02,  4.55253832e-02, -6.74533844e-03,\n",
       "          1.04207292e-01],\n",
       "        [-3.13466117e-02,  1.67700931e-01,  1.99401416e-02,\n",
       "          5.90358488e-02,  2.20305491e-02, -4.32983190e-01,\n",
       "          3.70323747e-01, -9.38385352e-02,  9.67840627e-02,\n",
       "          1.18864477e-02,  1.75568685e-01,  3.60262364e-01,\n",
       "          2.81865925e-01, -1.22642294e-01, -2.06929799e-02,\n",
       "          1.64229825e-01],\n",
       "        [-4.59666818e-01,  3.36798459e-01, -1.41308248e-01,\n",
       "         -4.99785021e-02,  2.31817886e-01, -2.91412205e-01,\n",
       "          4.64451939e-01, -5.17777987e-02, -2.70260215e-01,\n",
       "         -4.29177061e-02,  2.45464712e-01,  4.12122965e-01,\n",
       "          2.99583912e-01, -4.16807503e-01,  1.33413188e-02,\n",
       "         -1.41725987e-01],\n",
       "        [-3.33156995e-02,  2.60416359e-01, -3.91301960e-01,\n",
       "          3.59522291e-02,  1.85709149e-01, -7.31430054e-01,\n",
       "          1.42586172e-01,  5.66638336e-02,  1.25428930e-01,\n",
       "          5.31968065e-02,  4.41197067e-01,  3.12423974e-01,\n",
       "          6.60737276e-01, -4.47187066e-01, -1.93820596e-02,\n",
       "          1.12565741e-01],\n",
       "        [-4.26714689e-01,  1.54377848e-01, -1.28994852e-01,\n",
       "         -6.56387061e-02,  8.48542899e-02, -2.68372804e-01,\n",
       "          9.81641859e-02,  1.87592895e-03, -4.08052653e-02,\n",
       "         -1.56605020e-01,  7.03355297e-02,  1.15348406e-01,\n",
       "         -1.06903695e-01, -2.99997509e-01, -6.36869669e-03,\n",
       "         -4.53427806e-02],\n",
       "        [ 2.02073127e-01,  3.83691996e-01, -4.34935931e-03,\n",
       "         -8.76075849e-02,  9.80287120e-02, -7.29689360e-01,\n",
       "         -1.33518830e-01, -3.28922528e-03, -2.10390851e-01,\n",
       "         -3.81387137e-02,  3.18243176e-01, -1.19682059e-01,\n",
       "         -1.13518834e-02,  5.53447232e-02,  4.80008833e-02,\n",
       "          1.01932168e-01],\n",
       "        [-3.99124265e-01,  2.57187486e-01,  1.09620094e-01,\n",
       "          3.90483513e-02,  5.95638901e-02,  3.77556205e-01,\n",
       "          1.26216382e-01, -5.99727873e-03, -1.74144700e-01,\n",
       "          4.90107611e-02,  8.70805457e-02,  1.43021524e-01,\n",
       "          1.68430999e-01,  6.66438863e-02,  2.40955390e-02,\n",
       "         -2.10143756e-02],\n",
       "        [-3.38521838e-01,  2.63823390e-01, -1.07549362e-01,\n",
       "         -7.16730431e-02,  3.36303353e-01, -2.24402383e-01,\n",
       "          4.14065242e-01, -2.78835613e-02, -2.67124414e-01,\n",
       "          9.75488275e-02,  2.13691369e-01,  3.69023740e-01,\n",
       "          3.52530509e-01, -2.93538362e-01, -4.50541824e-03,\n",
       "         -7.15267882e-02],\n",
       "        [ 4.28039394e-02,  2.11553559e-01,  1.58687439e-02,\n",
       "          7.67279789e-02,  1.12627588e-01, -2.35273346e-01,\n",
       "          1.50611341e-01, -1.80389453e-02, -5.75979166e-02,\n",
       "          1.05154239e-01,  6.65968210e-02,  1.63444847e-01,\n",
       "         -2.48972122e-02, -1.49096951e-01, -1.06959827e-02,\n",
       "          5.22030145e-02],\n",
       "        [-2.32383117e-01,  3.77312034e-01, -2.06471384e-01,\n",
       "          1.60073116e-02,  2.51091629e-01, -4.29524362e-01,\n",
       "          4.61208194e-01,  3.21154483e-02, -2.69747436e-01,\n",
       "         -1.23979170e-02,  2.28829354e-01,  4.51226771e-01,\n",
       "          1.87123835e-01, -3.89674515e-01,  3.96821238e-02,\n",
       "         -6.23553954e-02],\n",
       "        [-9.00599062e-02,  1.97919592e-01, -8.69071484e-02,\n",
       "         -8.09667483e-02,  1.06977411e-01, -1.07741848e-01,\n",
       "          1.32530302e-01, -6.22520559e-02, -1.38625622e-01,\n",
       "         -7.61035383e-02,  2.70891227e-02,  1.43854901e-01,\n",
       "          2.84285061e-02, -2.04086870e-01,  3.71461995e-02,\n",
       "         -1.48417488e-01],\n",
       "        [-1.47863165e-01, -5.07012531e-02,  3.41262706e-02,\n",
       "         -3.41316350e-02, -9.32548419e-02,  6.64688647e-02,\n",
       "          1.59418613e-01, -4.67341691e-02, -1.34851187e-01,\n",
       "          6.07216358e-02, -9.63759944e-02,  1.24101669e-01,\n",
       "         -2.66770329e-02, -3.82089987e-02, -4.04589288e-02,\n",
       "         -2.25613892e-01],\n",
       "        [-1.28637984e-01, -1.42484054e-01,  6.36687428e-02,\n",
       "         -7.13272020e-02, -2.42653508e-02,  5.76522127e-02,\n",
       "         -7.91683868e-02, -3.09193153e-02, -1.86129764e-01,\n",
       "         -1.57418981e-01,  8.71940888e-03, -1.24573680e-02,\n",
       "         -8.31585154e-02,  1.55617455e-02,  4.94673960e-02,\n",
       "          1.24344956e-02],\n",
       "        [-7.41897151e-02, -1.92589894e-01, -8.63060281e-02,\n",
       "          2.59713992e-03,  2.69558549e-01,  1.83996245e-01,\n",
       "         -1.74906366e-02, -4.23168764e-02,  1.02663673e-01,\n",
       "         -1.15889035e-01, -2.33218104e-01, -4.99148294e-02,\n",
       "         -2.98367254e-03, -1.12476066e-01, -2.54868623e-02,\n",
       "         -6.73327297e-02],\n",
       "        [ 3.22601423e-02, -6.19453602e-02,  3.52675654e-03,\n",
       "         -2.35873237e-02,  6.78308010e-02, -1.15505934e-01,\n",
       "         -8.73268172e-02, -3.98741029e-02, -1.39938846e-01,\n",
       "          2.15956613e-01, -1.30227089e-01, -8.37367028e-02,\n",
       "         -2.45776176e-01, -1.01011045e-01,  1.96579956e-02,\n",
       "          4.11212519e-02],\n",
       "        [-2.85936266e-01, -1.44829238e-02,  9.48746204e-02,\n",
       "         -1.64532200e-01,  1.18478216e-01,  6.02365192e-03,\n",
       "          2.99387097e-01,  5.25003904e-03, -2.19019987e-02,\n",
       "         -1.91699579e-01, -2.39743348e-02,  3.15436780e-01,\n",
       "          6.61570625e-03, -2.21342221e-01, -2.98443083e-02,\n",
       "         -1.25313163e-01],\n",
       "        [-2.46656448e-01, -1.70595333e-01,  6.47695661e-02,\n",
       "         -1.37259588e-01, -4.15262282e-02,  5.04683144e-02,\n",
       "          8.82507116e-03,  1.27404043e-02, -3.69638860e-01,\n",
       "         -1.36218414e-01, -2.09735483e-01,  2.41579656e-02,\n",
       "         -8.88391435e-02, -6.94579333e-02,  1.61730535e-02,\n",
       "         -1.55924857e-01],\n",
       "        [-2.32825577e-01, -1.23457899e-02,  2.33598314e-02,\n",
       "         -1.75501872e-02,  2.10490212e-01, -3.32116276e-01,\n",
       "          4.40076321e-01, -3.74570191e-02, -7.71524534e-02,\n",
       "         -1.15179799e-01,  2.13952642e-02,  4.57552314e-01,\n",
       "          3.14974397e-01, -2.75147110e-01, -1.68789737e-02,\n",
       "         -6.42253086e-02]], dtype=float32),\n",
       " array([ 0.12758437,  0.21274468,  0.10797688,  0.06738459,  0.10482746,\n",
       "         0.03756063, -0.10370187, -0.00710144, -0.03592459,  0.02592874,\n",
       "         0.06551402, -0.09061142, -0.08501345,  0.05947424,  0.        ,\n",
       "         0.03753512], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizando os valores dos pesos na rede neural\n",
    "pesos0 = classificador.layers[0].get_weights()\n",
    "pesos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando \n",
    "previsores = classificador.predict(previsores_teste)\n",
    "previsores = (previsores > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer a comparaÃ§Ã£o entre as previsÃµes e os reultados que jÃ¡ conheÃ§o\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisao = accuracy_score(classe_teste, previsores)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a matriz de confusÃ£o\n",
    "matriz = confusion_matrix(classe_teste,previsores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 12],\n",
       "       [18, 75]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 572us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.746394754289747, 0.790209791877053]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fazendo o mesmo comparativo acima mas usando o keras agora\n",
    "resultado = classificador.evaluate(previsores_teste, classe_teste)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
